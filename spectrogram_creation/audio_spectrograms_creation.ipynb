{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satish\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#using librosa\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from scipy import signal\n",
    "#import lidis\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler,OneHotEncoder\n",
    "#Keras\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout\n",
    "# from keras.layers import Embedding\n",
    "# from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,fs=sample_rate,window='hann',nperseg=nperseg,noverlap=noverlap,detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  creation of spectrograms for train and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satish\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "pre_emphasis=0.97\n",
    "speech_commands = 'bed bird cat dog down eight five four go happy house left marvin nine no off on one right seven sheila six stop three tree two up wow yes'.split()\n",
    "for i in speech_commands:\n",
    "    count=0\n",
    "    for filename in os.listdir(f'D:/speech_dataset/google_data/{i}'):\n",
    "        #print(filename)\n",
    "        audio= f'D:/speech_dataset/google_data/{i}/{filename}'\n",
    "        f=f'{filename}'.split('.')\n",
    "        file=f[0]\n",
    "        y,sr=librosa.load(audio,sr=16000)\n",
    "        emphasized_signal = np.append(y[0], y[1:] - pre_emphasis * y[:-1])\n",
    "        freqs,times,spectrogram=log_specgram(emphasized_signal,sr)\n",
    "        s=librosa.feature.melspectrogram(emphasized_signal,sr,n_mels=128)\n",
    "        log_S = librosa.power_to_db(s, ref=np.max)\n",
    "        count+=1\n",
    "        #print(log_S)\n",
    "        plt.figure(figsize=(14,8))\n",
    "        plt.imshow(log_S.T,aspect='auto', origin='lower', extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "        plt.ylabel('freq in Hz')\n",
    "        plt.xlabel('time')\n",
    "        plt.title('Mel power spectrogram ')\n",
    "        #plt.colorbar(format='%+02.0f dB')-\n",
    "        plt.tight_layout()\n",
    "        if count<=300:\n",
    "            plt.savefig(f'D:/speech_dataset/train_images/{i}/{file}.jpg')\n",
    "        elif count>300 and count<=400:\n",
    "            plt.savefig(f'D:/speech_dataset/val_images/{i}/{file}.jpg')\n",
    "        else:\n",
    "            plt.clf()\n",
    "            break   \n",
    "        plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creation of spectrograms for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(f'D:/speech_dataset/test_data'):\n",
    "    #print(filename)\n",
    "    audio= f'D:/speech_dataset/test_data/{filename}'\n",
    "    f=f'{filename}'.split('.')\n",
    "    file=f[0]\n",
    "    y,sr=librosa.load(audio,sr=16000)\n",
    "    emphasized_signal = np.append(y[0], y[1:] - pre_emphasis * y[:-1])\n",
    "    freqs,times,spectrogram=log_specgram(emphasized_signal,sr)\n",
    "    s=librosa.feature.melspectrogram(emphasized_signal,sr,n_mels=128)\n",
    "    log_S = librosa.power_to_db(s, ref=np.max)\n",
    "    #count+=1\n",
    "    #print(log_S)\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.imshow(log_S.T,aspect='auto', origin='lower', extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "    plt.ylabel('freq in Hz')\n",
    "    plt.xlabel('time')\n",
    "    plt.title('Mel power spectrogram ')\n",
    "    #plt.colorbar(format='%+02.0f dB')-\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'D:/speech_dataset/test_data/test_images/{file}.jpg')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}