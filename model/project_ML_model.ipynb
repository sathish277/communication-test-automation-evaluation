{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satish\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as k\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout,BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers,optimizers\n",
    "# import gc\n",
    "# from path import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8700 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255.)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "directory= \"D:/speech_dataset/train_images/\",\n",
    "target_size=(192,192),\n",
    "#color_mode=\"rgb\",\n",
    "batch_size=32,\n",
    "class_mode = \"categorical\",\n",
    "shuffle=True,\n",
    "seed=42\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2900 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "#valid dataset\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "directory= \"D:/speech_dataset/val_images/\",\n",
    "target_size=(192,192),\n",
    "#color_mode=\"rgb\",\n",
    "batch_size=32,\n",
    "class_mode=\"categorical\",\n",
    "shuffle=True,\n",
    "seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#test dataset\n",
    "test_generator = datagen.flow_from_directory(\n",
    "directory=\"D:/speech_dataset/test_data/\",\n",
    "target_size=(192,192),\n",
    "#color_mode=\"rgb\",\n",
    "batch_size=1,\n",
    "class_mode=None,\n",
    "shuffle=False,\n",
    "seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step size of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "step_size_valid = valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\satish\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\satish\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding=\"same\",input_shape=(192,192,3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,(3,3),padding=\"same\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(128,(3,3),padding=\"same\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(128,(3,3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(29,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 192, 192, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 192, 192, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 190, 190, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 190, 190, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 95, 95, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 95, 95, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 95, 95, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 95, 95, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 93, 93, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 93, 93, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 46, 46, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 44, 44, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 44, 44, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 61952)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               31719936  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 29)                14877     \n",
      "=================================================================\n",
      "Total params: 32,049,501\n",
      "Trainable params: 32,049,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizers.rmsprop(lr=0.001,decay=1e-6),\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\satish\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "271/271 [==============================] - 4216s 16s/step - loss: 2.5047 - acc: 0.3017 - val_loss: 1.5804 - val_acc: 0.5448\n",
      "Epoch 2/5\n",
      "271/271 [==============================] - 3716s 14s/step - loss: 1.3315 - acc: 0.6119 - val_loss: 1.1128 - val_acc: 0.6778\n",
      "Epoch 3/5\n",
      "271/271 [==============================] - 4976s 18s/step - loss: 0.8266 - acc: 0.7564 - val_loss: 0.9415 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "271/271 [==============================] - 4148s 15s/step - loss: 0.6035 - acc: 0.8263 - val_loss: 1.0474 - val_acc: 0.7622\n",
      "Epoch 5/5\n",
      "271/271 [==============================] - 4811s 18s/step - loss: 0.4756 - acc: 0.8624 - val_loss: 0.8467 - val_acc: 0.7842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8455105931855312, 0.7841701535832766]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting our model\n",
    "model.fit_generator(generator = train_generator,steps_per_epoch = step_size_train,\n",
    "                    validation_data = valid_generator,validation_steps = step_size_valid,\n",
    "                   epochs = 5)\n",
    "model.evaluate_generator(generator = valid_generator,steps = step_size_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model,open('D:/final_project_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\satish\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\satish\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\satish\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model=pickle.load(open('D:/final_model/final_project_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 352ms/step\n",
      "bed --> 3.8102060556411743\n",
      "cat --> 0.4114062525331974\n",
      "five --> 90.25172591209412\n",
      "happy --> 98.97674918174744\n",
      "left --> 52.98369526863098\n",
      "one --> 31.525087356567383\n",
      "seven --> 55.30551075935364\n",
      "sheila --> 99.95682835578918\n",
      "wow --> 19.99691128730774\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)\n",
    "#print(float(pred[0][0]))\n",
    "labels = (train_generator.class_indices)\n",
    "#print(labels)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "predicted_class_indices[0:9]\n",
    "percentage=[]\n",
    "prediction=['bed','cat','five','happy','left','one','seven','sheila','wow']\n",
    "labels=(train_generator.class_indices)\n",
    "c=0\n",
    "for i in prediction:\n",
    "    index=labels[i]\n",
    "    #print(index)\n",
    "    percent=pred[c][index]\n",
    "    #print(percent)\n",
    "    percent=float(percent)\n",
    "    percent=percent*100\n",
    "    percentage.append(percent)\n",
    "    c+=1\n",
    "#Fetch labels from train gen for testing\n",
    "#print(labels)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "#predictions = [labels[k] for k in predicted_class_indices]\n",
    "for i in range(9):\n",
    "    print(f'{prediction[i]} --> {percentage[i]}')\n",
    "#print(predictions[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "# test_generator.reset()\n",
    "# pred=model.predict_generator(test_generator,\n",
    "# steps=STEP_SIZE_TEST,\n",
    "# verbose=1)\n",
    "# pred[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}